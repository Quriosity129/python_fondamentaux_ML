{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXZ6f6FXKrycCedyqqJ6xm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"eSUCjZEPafxU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On travaille de nouveau sur le jeu de données de voitures vu au TD précédent."],"metadata":{"id":"LDwTw6r0aaVG"}},{"cell_type":"code","source":["df = pd.read_csv('https://github.com/mahatosourav91/Linear-Regression/raw/master/CarPrice_Assignment.csv')\n","df.head()"],"metadata":{"id":"4Fb8q1ByjbTv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le but est toujours le même : prédire le prix d'une voiture à partir des variables explicatives disponibles.\n","\n","Maintenant que nous travaillons avec des arbres de décision, on va pouvoir facilement utiliser des variables qualitatives (par exemple, `fueltype`) dans le modèle. Cependant, il faut d'abord transformer ces variables en un type numérique, les strings n'étant pas gérés automatiquement par `scikit-learn`.\n","\n","1. En utilisant `LabelEncoder`, faire cette transformation pour les colonnes correspondantes."],"metadata":{"id":"IAqO6ekfa8uc"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n"],"metadata":{"id":"YWAvHHGhbgfz","executionInfo":{"status":"ok","timestamp":1716553345292,"user_tz":-120,"elapsed":15,"user":{"displayName":"Alexandre Tuel","userId":"09272815080792413028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Définir la colonne `price` comme cible, et prendre le reste du dataset (hormis les colonnes `car_ID` et `CarName`) comme matrice de design. Diviser en jeu de données d'entraînement et de test."],"metadata":{"id":"vEIkMDSKcFHF"}},{"cell_type":"code","source":[],"metadata":{"id":"LZa86Cw6bXVJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Entraîner une forêt aléatoire sur les donnés d'entraînement avec `n_estimators=200` et `max_depth=4`, sans toucher aux autres paramètres. Calculer le $r^2$ et la RMSE sur les données de test. Normaliser la RMSE par l'écart-type des données de test."],"metadata":{"id":"a7At9c11qq85"}},{"cell_type":"code","source":[],"metadata":{"id":"43GKtgvqajrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On va maintenant chercher à optimiser les paramètres de la forêt aléatoire avec `GridSearchCV`.\n","\n","4. Implémenter une recherche de paramètres optimaux (`n_estimators` et `max_depth`) pour un `RandomForestRegressor` avec `GridSearchCV`. Attention à ne pas faire tourner sur trop de combinaisons de paramètres, sinon ça risque de prendre longtemps..."],"metadata":{"id":"-XoA5bzjxu75"}},{"cell_type":"code","source":[],"metadata":{"id":"BkZZGz4gjYZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Afficher l'erreur d'entraînement et de validation en fonction du nombre d'arbres (erreur moyennée sur `max_depth`)."],"metadata":{"id":"PTE3MlKxz0ZO"}},{"cell_type":"code","source":[],"metadata":{"id":"-s8rgp_bjk6a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Extraire le modèle optimal, et calculer sa performance sur les données de test."],"metadata":{"id":"IUkQTBkvz5tr"}},{"cell_type":"code","source":[],"metadata":{"id":"HhJlMg6zjmW5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. En prenant `n_estimators=100` et `max_depth=12`, trouver un `max_features` optimal via `GridSearchCV`.\n","\n"],"metadata":{"id":"NlqJ1Wb6fxxx"}},{"cell_type":"code","source":[],"metadata":{"id":"YIeNI0DbjoIC"},"execution_count":null,"outputs":[]}]}